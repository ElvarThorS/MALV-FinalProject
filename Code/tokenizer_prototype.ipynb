{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/siruspalsson1/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"The Bituminous coal strike of 1977-1978 was a 110-day national coal strike in the United States led by the United Mine Workers of America. It began December 6, 1977, and ended on March 19, 1978. It is generally considered a successful union strike, although the contract was not beneficial to union members. Since the 1940s, the United Mine Workers of America (UMWA) had negotiated a nationwide National Coal Wage Agreement with the Bituminous Coal Operators Association (BCOA), a group of large coal mine operators. The three-year agreements covered national bargaining issues such as wages, health and pension benefits, workplace health and safety, and work rules. Local agreements, far more limited in scope, were negotiated by each individual local affiliate of UMWA.\"\n",
    "\n",
    "sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bituminous coal strike of 1977-1978 was a 110-day national coal strike in the United States led by the United Mine Workers of America.\n",
      "It began December 6, 1977, and ended on March 19, 1978.\n",
      "It is generally considered a successful union strike, although the contract was not beneficial to union members.\n",
      "Since the 1940s, the United Mine Workers of America (UMWA) had negotiated a nationwide National Coal Wage Agreement with the Bituminous Coal Operators Association (BCOA), a group of large coal mine operators.\n",
      "The three-year agreements covered national bargaining issues such as wages, health and pension benefits, workplace health and safety, and work rules.\n",
      "Local agreements, far more limited in scope, were negotiated by each individual local affiliate of UMWA.\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences: print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Bituminous', 'coal', 'strike', 'of', '1977-1978', 'was', 'a', '110-day', 'national', 'coal', 'strike', 'in', 'the', 'United', 'States', 'led', 'by', 'the', 'United', 'Mine', 'Workers', 'of', 'America', '.'], ['It', 'began', 'December', '6', ',', '1977', ',', 'and', 'ended', 'on', 'March', '19', ',', '1978', '.'], ['It', 'is', 'generally', 'considered', 'a', 'successful', 'union', 'strike', ',', 'although', 'the', 'contract', 'was', 'not', 'beneficial', 'to', 'union', 'members', '.'], ['Since', 'the', '1940s', ',', 'the', 'United', 'Mine', 'Workers', 'of', 'America', '(', 'UMWA', ')', 'had', 'negotiated', 'a', 'nationwide', 'National', 'Coal', 'Wage', 'Agreement', 'with', 'the', 'Bituminous', 'Coal', 'Operators', 'Association', '(', 'BCOA', ')', ',', 'a', 'group', 'of', 'large', 'coal', 'mine', 'operators', '.'], ['The', 'three-year', 'agreements', 'covered', 'national', 'bargaining', 'issues', 'such', 'as', 'wages', ',', 'health', 'and', 'pension', 'benefits', ',', 'workplace', 'health', 'and', 'safety', ',', 'and', 'work', 'rules', '.'], ['Local', 'agreements', ',', 'far', 'more', 'limited', 'in', 'scope', ',', 'were', 'negotiated', 'by', 'each', 'individual', 'local', 'affiliate', 'of', 'UMWA', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Bituminous', 'coal', 'strike', 'of', '1977-1978', 'was', 'a', '110-day', 'national', 'coal', 'strike', 'in', 'the', 'United', 'States', 'led', 'by', 'the', 'United', 'Mine', 'Workers', 'of', 'America', '.']\n",
      "['It', 'began', 'December', '6', ',', '1977', ',', 'and', 'ended', 'on', 'March', '19', ',', '1978', '.']\n",
      "['It', 'is', 'generally', 'considered', 'a', 'successful', 'union', 'strike', ',', 'although', 'the', 'contract', 'was', 'not', 'beneficial', 'to', 'union', 'members', '.']\n",
      "['Since', 'the', '1940s', ',', 'the', 'United', 'Mine', 'Workers', 'of', 'America', '(', 'UMWA', ')', 'had', 'negotiated', 'a', 'nationwide', 'National', 'Coal', 'Wage', 'Agreement', 'with', 'the', 'Bituminous', 'Coal', 'Operators', 'Association', '(', 'BCOA', ')', ',', 'a', 'group', 'of', 'large', 'coal', 'mine', 'operators', '.']\n",
      "['The', 'three-year', 'agreements', 'covered', 'national', 'bargaining', 'issues', 'such', 'as', 'wages', ',', 'health', 'and', 'pension', 'benefits', ',', 'workplace', 'health', 'and', 'safety', ',', 'and', 'work', 'rules', '.']\n",
      "['Local', 'agreements', ',', 'far', 'more', 'limited', 'in', 'scope', ',', 'were', 'negotiated', 'by', 'each', 'individual', 'local', 'affiliate', 'of', 'UMWA', '.']\n"
     ]
    }
   ],
   "source": [
    "for token_sent in tokenized_sentences: print(token_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = []\n",
    "\n",
    "for index, sent in enumerate(tokenized_sentences):\n",
    "    for token in sent:\n",
    "        tokenized_data.append({\n",
    "                        'Sentence #': f\"Sentence: {index+1}\",\n",
    "                        'Word': token,\n",
    "                        'Tag': 'O'\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Sentence #': 'Sentence: 1', 'Word': 'The', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'Bituminous', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'coal', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'strike', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'of', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': '1977-1978', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'was', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'a', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': '110-day', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'national', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'coal', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'strike', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'in', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'the', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'United', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'States', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'led', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'by', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'the', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'United', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'Mine', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'Workers', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'of', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': 'America', 'Tag': 'O'}, {'Sentence #': 'Sentence: 1', 'Word': '.', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': 'It', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': 'began', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': 'December', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': '6', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': '1977', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': 'and', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': 'ended', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': 'on', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': 'March', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': '19', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': '1978', 'Tag': 'O'}, {'Sentence #': 'Sentence: 2', 'Word': '.', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'It', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'is', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'generally', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'considered', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'a', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'successful', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'union', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'strike', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'although', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'the', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'contract', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'was', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'not', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'beneficial', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'to', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'union', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': 'members', 'Tag': 'O'}, {'Sentence #': 'Sentence: 3', 'Word': '.', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Since', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'the', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': '1940s', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'the', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'United', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Mine', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Workers', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'of', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'America', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': '(', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'UMWA', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': ')', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'had', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'negotiated', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'a', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'nationwide', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'National', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Coal', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Wage', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Agreement', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'with', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'the', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Bituminous', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Coal', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Operators', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'Association', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': '(', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'BCOA', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': ')', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'a', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'group', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'of', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'large', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'coal', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'mine', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': 'operators', 'Tag': 'O'}, {'Sentence #': 'Sentence: 4', 'Word': '.', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'The', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'three-year', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'agreements', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'covered', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'national', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'bargaining', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'issues', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'such', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'as', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'wages', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'health', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'and', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'pension', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'benefits', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'workplace', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'health', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'and', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'safety', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'and', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'work', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': 'rules', 'Tag': 'O'}, {'Sentence #': 'Sentence: 5', 'Word': '.', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'Local', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'agreements', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'far', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'more', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'limited', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'in', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'scope', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': ',', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'were', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'negotiated', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'by', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'each', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'individual', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'local', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'affiliate', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'of', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': 'UMWA', 'Tag': 'O'}, {'Sentence #': 'Sentence: 6', 'Word': '.', 'Tag': 'O'}]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article data saved to tokenized_event_data.csv\n"
     ]
    }
   ],
   "source": [
    "filename = \"tokenized_event_data\"\n",
    "df = pd.DataFrame(tokenized_data)\n",
    "df.to_csv(f\"{filename}.csv\", index=False)\n",
    "print(f\"Article data saved to {filename}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>The</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Bituminous</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>coal</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>strike</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>1977-1978</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>110-day</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>national</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>coal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>strike</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>United</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>States</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>led</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>by</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>United</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #        Word Tag\n",
       "0   Sentence: 1         The   B\n",
       "1   Sentence: 1  Bituminous   I\n",
       "2   Sentence: 1        coal   I\n",
       "3   Sentence: 1      strike   I\n",
       "4   Sentence: 1          of   I\n",
       "5   Sentence: 1   1977-1978   I\n",
       "6   Sentence: 1         was   O\n",
       "7   Sentence: 1           a   O\n",
       "8   Sentence: 1     110-day   O\n",
       "9   Sentence: 1    national   O\n",
       "10  Sentence: 1        coal   O\n",
       "11  Sentence: 1      strike   O\n",
       "12  Sentence: 1          in   O\n",
       "13  Sentence: 1         the   O\n",
       "14  Sentence: 1      United   O\n",
       "15  Sentence: 1      States   O\n",
       "16  Sentence: 1         led   O\n",
       "17  Sentence: 1          by   O\n",
       "18  Sentence: 1         the   O\n",
       "19  Sentence: 1      United   O"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafilename = 'tagged_event_data.csv'\n",
    "data = pd.read_csv(datafilename, encoding='unicode_escape')\n",
    "data['Tag'] = data['Tag'].apply(str.upper)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    142\n",
       "Word          142\n",
       "Tag           142\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "O    132\n",
       "I      8\n",
       "B      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
    "frequencies = data.Tag.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 0, 'I': 1, 'O': 2}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B', 1: 'I', 2: 'O'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/xgr43d3x3gv_27t5cflz7xz00000gp/T/ipykernel_37115/502307167.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>The</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Bituminous</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>coal</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>strike</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>1977-1978</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>110-day</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>national</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #        Word Tag\n",
       "0  Sentence: 1         The   B\n",
       "1  Sentence: 1  Bituminous   I\n",
       "2  Sentence: 1        coal   I\n",
       "3  Sentence: 1      strike   I\n",
       "4  Sentence: 1          of   I\n",
       "5  Sentence: 1   1977-1978   I\n",
       "6  Sentence: 1         was   O\n",
       "7  Sentence: 1           a   O\n",
       "8  Sentence: 1     110-day   O\n",
       "9  Sentence: 1    national   O"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill any missing tags\n",
    "data = data.fillna(method='ffill')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>The</td>\n",
       "      <td>B</td>\n",
       "      <td>The Bituminous coal strike of 1977-1978 was a ...</td>\n",
       "      <td>B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Bituminous</td>\n",
       "      <td>I</td>\n",
       "      <td>The Bituminous coal strike of 1977-1978 was a ...</td>\n",
       "      <td>B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>coal</td>\n",
       "      <td>I</td>\n",
       "      <td>The Bituminous coal strike of 1977-1978 was a ...</td>\n",
       "      <td>B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>strike</td>\n",
       "      <td>I</td>\n",
       "      <td>The Bituminous coal strike of 1977-1978 was a ...</td>\n",
       "      <td>B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>I</td>\n",
       "      <td>The Bituminous coal strike of 1977-1978 was a ...</td>\n",
       "      <td>B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #        Word Tag  \\\n",
       "0  Sentence: 1         The   B   \n",
       "1  Sentence: 1  Bituminous   I   \n",
       "2  Sentence: 1        coal   I   \n",
       "3  Sentence: 1      strike   I   \n",
       "4  Sentence: 1          of   I   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  The Bituminous coal strike of 1977-1978 was a ...   \n",
       "1  The Bituminous coal strike of 1977-1978 was a ...   \n",
       "2  The Bituminous coal strike of 1977-1978 was a ...   \n",
       "3  The Bituminous coal strike of 1977-1978 was a ...   \n",
       "4  The Bituminous coal strike of 1977-1978 was a ...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "1  B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "2  B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "3  B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4  B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column called \"sentence\", grouping words by sentence \n",
    "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
    "# create a new column called \"word_labels\", grouping tags by sentence \n",
    "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Bituminous coal strike of 1977-1978 was a ...</td>\n",
       "      <td>B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It began December 6 , 1977 , and ended on Marc...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is generally considered a successful union ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since the 1940s , the United Mine Workers of A...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,I,I,I,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The three-year agreements covered national bar...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The Bituminous coal strike of 1977-1978 was a ...   \n",
       "1  It began December 6 , 1977 , and ended on Marc...   \n",
       "2  It is generally considered a successful union ...   \n",
       "3  Since the 1940s , the United Mine Workers of A...   \n",
       "4  The three-year agreements covered national bar...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "1                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "2              O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "3  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,I,I,I,O,O,...  \n",
       "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep \"sentence\" and \"word_labels\" columns, and drop duplicates\n",
    "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since the 1940s , the United Mine Workers of America ( UMWA ) had negotiated a nationwide National Coal Wage Agreement with the Bituminous Coal Operators Association ( BCOA ) , a group of large coal mine operators .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[3].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[3].word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Bituminous coal strike of 1977-1978 was a 110-day national coal strike in the United States led by the United Mine Workers of America .'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'I',\n",
       " 'I',\n",
       " 'I',\n",
       " 'I',\n",
       " 'I',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word_labels[0].split(\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B,I,I,I,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE TOKENIZER TO bert-base-cased\n",
    "\n",
    "# Model HyperParameters and Tokenizer\n",
    "\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset Class\n",
    "#     pandas dataframe to pytorch tensors\n",
    "#     each sentence tokenized\n",
    "#     special BERT tokens added\n",
    "#     tokens padded or truncated based on MAX_LENGTH\n",
    "#     attention mask created\n",
    "#     labels created from word_labels column\n",
    "\n",
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index].strip().split()  \n",
    "        word_labels = self.data.word_labels[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             is_pretokenized=True, \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (6, 2)\n",
      "TRAIN Dataset: (4, 2)\n",
      "TEST Dataset: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "\n",
    "train_size = 0.75\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n",
      "Keyword arguments {'is_pretokenized': True} not recognized.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'offset_mapping'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 34\u001b[0m, in \u001b[0;36mdataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m labels \u001b[38;5;241m=\u001b[39m [labels_to_ids[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m word_labels] \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# create an empty array of -100 of length max_length\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m encoded_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(\u001b[43mencoding\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffset_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# set only labels whose first offset position is 0 and the second is not 0\u001b[39;00m\n\u001b[1;32m     37\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:270\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mIf the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03metc.).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03mwith the constraint of slice.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings[item]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'offset_mapping'"
     ]
    }
   ],
   "source": [
    "for item in training_set:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizers\u001b[49m\u001b[38;5;241m.\u001b[39m__version__\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizers' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
